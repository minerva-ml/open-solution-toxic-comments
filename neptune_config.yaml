project-key: TOX

name: toxic
tags: [glove, scnn, sgd]

parameters:
  # Environment
  data_dir: /mnt/ml-team/minerva/toxic/data
  experiment_dir: /mnt/ml-team/minerva/toxic/experiments/glove_scnn
  embedding_filepath: /mnt/ml-team/minerva/pretrained/glove.840B.300d.txt
  overwrite: false
  num_workers: -2
  # Preprocessing
  max_features_char: 2000
  max_features_word: 100000
  maxlen_char: 512
  maxlen_words: 64
  char_embedding_size: 300
  word_embedding_size: 300
  char_ngram_max: 4
  # Deep Pyramid Architecture
  dpcnn_filter_nr: 64
    #value: [64, 300]
  dpcnn_kernel_size: 6
    #value: [3, 6]
  dpcnn_repeat_block: 2
    #value: [1, 2]
  dpcnn_dense_size: 256
    #value: [64, 512]
  dpcnn_repeat_dense:
    #value: [1, 2]
  # Shallow CNN Architecture
  scnn_filter_nr:
    value: [64, 256]
  scnn_kernel_size:
    value: [3, 6]
  scnn_dense_size:
    value: [64, 256]
  scnn_repeat_dense:
    value: [1, 2]
  # Char CNN Architecture
  char_cnn_filter_nr: 64
  char_cnn_kernel_size: 3
  char_cnn_dense_size: 256
  char_cnn_repeat_dense: 2
  # LSTM Architecture
  lstm_unit_nr: 64
  lstm_repeat_block: 3
  lstm_dense_nr: 2
  lstm_dense_size: 256
  lstm_repeat_dense: 2
  global_pooling: False
  # General Architecture
  use_prelu: True
  trainable_embedding: True
  # Log Reg Params
  log_reg_c: 4.0
  # Training schedule
  epochs_nr: 1000
  batch_size_train: 128
  batch_size_inference: 128
  lr: 0.01
  momentum: 0.9
  gamma: 0.97
  patience: 10
  # Regularization
  l2_reg_convo: 0.0002
  l2_reg_dense: 0.0
  dropout_lstm: 0.2
  dropout_convo: 0.2
  dropout_dense: 0.5

metric:
  channel: 'Final Validation Score'
  goal: minimize

exclude:
  - output
  - neptune.log
  - offline_job.log
  - .git
  - .idea
  - .ipynb_checkpoints
