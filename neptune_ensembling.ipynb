{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_log_loss(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    columns = y_true.shape[1]\n",
    "    column_losses = []\n",
    "    for i in range(0, columns):\n",
    "        column_losses.append(log_loss(y_true[:, i], y_pred[:, i]))\n",
    "    return np.array(column_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = ['toxic', 'severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "SINGLE_DIR = '/public/toxic_comments/single_model_predictions'\n",
    "\n",
    "BWCL_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'logreg_bad_word_count.csv') # 0.0669\n",
    "CVDCNN_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'char_vdcnn.csv') # 0.0435\n",
    "CLOGREG_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'logreg_count.csv') # 0.126\n",
    "GDPCNN_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'glove_dpcnn.csv') # 0.0422\n",
    "GLSTM_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'glove_lstm.csv') # 0.0417\n",
    "GSCNN_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'glove_scnn.csv') # 0.0427\n",
    "TFIDIF_LOGREG_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'logreg_tfidf.csv') # 0.0459\n",
    "WLSTM_VALID_PATH = os.path.join(SINGLE_DIR, 'valid', 'word_lstm.csv') # 0.0486\n",
    "\n",
    "VALID_LABELS_PATH = os.path.join(SINGLE_DIR, 'valid', 'valid_split.csv')\n",
    "\n",
    "BWCL_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'logreg_bad_word_count.csv')\n",
    "CVDCNN_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'char_vdcnn.csv')\n",
    "CLOGREG_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'logreg_count.csv')\n",
    "GDPCNN_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'glove_dpcnn.csv')\n",
    "GLSTM_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'glove_lstm.csv')\n",
    "GSCNN_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'glove_scnn.csv')\n",
    "TFIDIF_LOGREG_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'logreg_tfidf.csv')\n",
    "WLSTM_TEST_PATH = os.path.join(SINGLE_DIR, 'test', 'word_lstm.csv')\n",
    "\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(SINGLE_DIR, 'test', 'sample_submission.csv')\n",
    "ENSEMBLE_SUBMISSION_PATH = os.path.join(SINGLE_DIR, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set Level 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_count_logreg_valid = pd.read_csv(BWCL_VALID_PATH)\n",
    "char_vdcnn_valid = pd.read_csv(CVDCNN_VALID_PATH)\n",
    "count_logreg_valid = pd.read_csv(CLOGREG_VALID_PATH)\n",
    "glove_dpcnn_valid = pd.read_csv(GDPCNN_VALID_PATH)\n",
    "glove_lstm_valid = pd.read_csv(GLSTM_VALID_PATH)\n",
    "glove_scnn_valid = pd.read_csv(GSCNN_VALID_PATH)\n",
    "tfidf_logreg_valid = pd.read_csv(TFIDIF_LOGREG_VALID_PATH)\n",
    "word_lstm_valid = pd.read_csv(WLSTM_VALID_PATH)\n",
    "\n",
    "labels_valid = pd.read_csv(VALID_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_count_logreg_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.hstack([bad_word_count_logreg_valid.drop('id',axis=1), \n",
    "                     char_vdcnn_valid.drop('id',axis=1), \n",
    "                     count_logreg_valid.drop('id',axis=1), \n",
    "                     glove_dpcnn_valid.drop('id',axis=1), \n",
    "                     glove_lstm_valid.drop('id',axis=1), \n",
    "                     glove_scnn_valid.drop('id',axis=1), \n",
    "                     tfidf_logreg_valid.drop('id',axis=1), \n",
    "                     word_lstm_valid.drop('id',axis=1)])\n",
    "\n",
    "y_valid_multilabel = labels_valid[LABEL_COLUMNS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Level 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_count_logreg_test = pd.read_csv(BWCL_TEST_PATH)\n",
    "char_vdcnn_test = pd.read_csv(CVDCNN_TEST_PATH)\n",
    "count_logreg_test = pd.read_csv(CLOGREG_TEST_PATH)\n",
    "glove_dpcnn_test = pd.read_csv(GDPCNN_TEST_PATH)\n",
    "glove_lstm_test = pd.read_csv(GLSTM_TEST_PATH)\n",
    "glove_scnn_test = pd.read_csv(GSCNN_TEST_PATH)\n",
    "tfidf_logreg_test = pd.read_csv(TFIDIF_LOGREG_TEST_PATH)\n",
    "word_lstm_test = pd.read_csv(WLSTM_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack([bad_word_count_logreg_test.drop('id',axis=1), \n",
    "                    char_vdcnn_test.drop('id',axis=1), \n",
    "                    count_logreg_test.drop('id',axis=1), \n",
    "                    glove_dpcnn_test.drop('id',axis=1), \n",
    "                    glove_lstm_test.drop('id',axis=1), \n",
    "                    glove_scnn_test.drop('id',axis=1), \n",
    "                    tfidf_logreg_test.drop('id',axis=1), \n",
    "                    word_lstm_test.drop('id',axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "for i in range(6):\n",
    "    y_valid_one_label = y_valid_multilabel[:,i]\n",
    "    estimator = LogisticRegression()\n",
    "    estimator.fit(X_valid, y_valid_one_label)\n",
    "    estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = []\n",
    "for estimator in estimators:\n",
    "    y_test_pred_one_label = estimator.predict_proba(X_test)\n",
    "    y_test_pred.append(y_test_pred_one_label)\n",
    "y_test_pred = np.stack(y_test_pred, axis=1)[...,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "submission[LABEL_COLUMNS] = y_test_pred\n",
    "submission.to_csv(ENSEMBLE_SUBMISSION_PATH, index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_py3",
   "language": "python",
   "name": "dl_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
